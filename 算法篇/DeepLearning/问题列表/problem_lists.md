# 基础相关问题

## 1. 如何设置网络初始值

Xavier（glorot initialization）和Kaiming（He intialization）。

## 2. 为什么推荐使用高斯分布？
当我们由于缺乏关于某个实数上分布的先验知识而不知道该选择怎样的形式时，正态分布是默认的比较好的选择，其中有两个原因：
   1. 我们想要建模的很多分布的真实情况是比较接近正态分布的。**中心极限定理（central limit theorem）**说明很多独立随机变量的和近似服从正态分布。这意味着在实际中，很多复杂系统都可以被成功地建模成正态分布的噪声，即使系统可以被分解成一些更结构化的部分。
   2. 在具有相同方差的所有可能的概率分布中，正态分布在实数上具有最大的不确定性。因此，我们可以认为**正态分布是对模型加入的先验知识量最少的分布**。

正态分布有单边量和多变量形式， 
- 单变量  
对于单边量$x \in R$，高斯分布的参数为均值$\mu \in R$和方差$\sigma^2>0$，其概率密度函数
$$
p(x|u,\sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}}exp\left\{-\frac{(x-\mu)^2}{2\sigma^2}\right\}
$$
其均值和方差分别为$\mu$和$\sigma^2$   
- 多变量   
对于$d$维向量$\boldsymbol{x}$，多元高斯分布的参数为$d$维向量$\boldsymbol{\mu}$和$d \times d$的对称正定协方差矩阵$\boldsymbol{\Sigma}$，概率密度函数 
$$
p(\boldsymbol{x}|\boldsymbol{\mu}, \boldsymbol{\Sigma}) = \frac{1}{\sqrt{(2\pi)^d det(\boldsymbol{\Sigma})}}exp\left\{-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^T\boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu})\right\}
$$



## 3. 如何避免深度学习中的病态，鞍点，梯度爆炸，梯度弥散？

### 3.1 病态  
简单来说，深度学习中的病态问题指的就是学习/优化变的困难，需要更多的迭代次数才能达到相同的精度。    
更具体的，导致病态的原因是问题的条件数（condition number）非常大，其中**条件数 = 函数梯度最大变化速度 / 梯度最小变化速度**（对于二阶可导函数，条件数的严格定义是：Hessian矩阵最大特征值的上界 / 最小特征值的下界）。    
**条件数大意味着目标函数在有的地方（或有的方向）变化很快、有的地方很慢**，比较不规律，从而很难用当前的局部信息（梯度）去比较准确地预测最优点所在的位置，只能一步步缓慢的逼近最优点，从而优化时需要更多的迭代次数。

#### 3.1.1 如何避免病态

知道了什么是病态，那么所有有利于加速训练的方法都属于在避免病态，其中最主要的还是优化算法。

深度学习主要使用的优化算法是梯度下降，所以避免病态问题的关键是改进梯度下降算法：

- 随机梯度下降（SGD）、批量随机梯度下降   
- 动态的学习率   
- 带动量的SGD   

网络的病态问题通常与训练数据、网络结构以及网络的初始化权重有关。常见的问题是输入训练数据过大、网络层结构大小不一、初始权重过大或过小。所以在网络训练之前需要进行precondition。   
数学上，precondition是将病态问题转化为更容易优化求解的问题，通常通过乘以一个preconditioner 矩阵来完成转化。如下图所示，转化前需要4次迭代收敛到f=1,转化后仅需一次迭代。 
![](../../../pics/precondition.png)

### 3.2 鞍点
对于很多高维非凸函数（神经网络）而言，局部极小值/极大值事实上都远少于另一类梯度为零的点：鞍点

- 鞍点定义
神经网络优化问题中的鞍点即一个维度向上倾斜且另一维度向下倾斜的点，或者说**在一个方向是极大值，另一个方向是极小值的点**。 
该点处的梯度为0,该点出的Hessian矩阵是不定的（特征值有正有负）。  

#### 3.2.1 如何避免鞍点
优化算法上使用自适应学习率的优化算法（AdaDelta, Adam等）

### 3.3 梯度爆炸&消失  
梯度消失与梯度爆炸其实是一种情况，两种情况下梯度消失经常出现，一是在深层网络中，二是采用了不合适的激活函数，比如sigmoid。梯度爆炸一般出现在深层网络和权值初始化值太大的情况下。

#### 3.3.1 梯度爆炸&消失的原因  
以一个四层的全连接网络为例，假设每一层的输出为$f_i(x)$，其中$i$表示第$i$层的输入，也就是$i-1$层的输出，$f$是激活函数，那么有$f_{i+1}=f(f_i*w_{i+1}+b_{i+1})$，简单记为$f_{i+1}=f(f_i*w_{i+1})$。   
其中权重的更近基于BP算法，$w \leftarrow w+\Delta w$，给定学习率$\alpha$，得出$\Delta w=-\alpha \frac{\partial Loss}{\partial w}$，以更新第二个隐含层的权值为例，根据链式求导法则，有$\Delta w_2=\frac{\partial Loss}{\partial w}=\frac{\partial Loss}{\partial f_4} \frac{\partial f_4}{\partial f_3} \frac{\partial f_3}{\partial f_2} \frac{\partial f_2}{\partial w_2}$，其中$\frac{\partial f_4}{\partial f_3}$就是对激活函数进行求偏导，如果此不分大于1,那么层数增多的时候，最终求得的梯度将以指数的形式增加，即**梯度爆炸**，如果此部分小于1,随着层数的增加，求出的梯度信息将会以指数的形式衰减，即**梯度消失**。   

**从深层网络角度来讲，不同的层学习的速度差异很大，表现为网络中靠近输出的层学习的情况很好，靠近输入的层学习的很慢，有时甚至训练了很久，前几层的权值和刚开始随机初始化的值差不多。**因此，梯度消失、爆炸，其根本原因在于反向传播训练法则，属于先天不足，另外多说一句，Hinton提出capsule的原因就是为了彻底抛弃反向传播，如果真能大范围普及，那将是一个巨大的变革。

#### 3.3.2 sigmoid激活函数   
以sigmoid函数为激活函数为例，在反向传播更新参数时，需要对激活函数求导，sigmoid函数求导后为$deri(\sigma(z))=\sigma(z)(1-\sigma(z))$，其函数图像和原图像如下，  
![](../../../pics/sigmoid.png) 
从上图sigmoid函数取值趋于饱和时，其导数越来越接近于0，越来越小，很容易发生梯度消失。

#### 3.3.3 避免梯度消失&爆炸
现实中，往往梯度消失出现的更多。   

- 梯度剪切   
该方式主要是针对梯度爆炸提出的，设置一个剪切阈值，如果梯度超过这个阈值，就将其限制在这个范围内   
- 网中添加正则项
  - 损失中加L2   
  可以让整体参数偏小，以防止梯度爆炸。  
  - BN(Batch Normalization)    
  将整体权重放缩到均值为零方差为1的标准正态分布，具体可以参考**算法篇/deep_learning/深度学习基础**
  
- 激活函数   
relu函数的导数在正数部分是恒等于1的，可以解决梯度消失和爆炸的问题且加速了网络的训练   

- 网络结构   
目前很多网络结构的设计在一定程度上可以避免梯度爆炸和消失。比如ResNet和LSTM

### 3.4 参考资源  
- [神经网络激活函数sigmoid relu tanh 为什么sigmoid 容易梯度消失](https://blog.csdn.net/danyhgc/article/details/73850546)   
- [详解机器学习中的梯度消失、爆炸原因及其解决方法](https://blog.csdn.net/qq_25737169/article/details/78847691)



## 4. 在深度神经网络中，引入了隐藏层（非线性单元），放弃了训练问题的凸性，其意义何在？

放弃训练问题的凸性，简单来说，就是放弃寻求问题的最优解。

非线性单元的加入，使训练问题不再是一个凸优化问题。这意味着神经网络很难得到最优解，即使一个只有两层和三个节点的简单神经网络，其训练优化问题仍然是 NP-hard 问题 (Blum & Rivest, 1993).

但即使如此，使用神经网络也是利大于弊的：

- 人类设计者只需要寻找正确的**函数族**即可，而不需要去寻找精确的函数。
- 使用简单的梯度下降优化方法就可以高效地找到足够好的局部最小值
- 增强了模型的学习/拟合能力，如原书中所说“ maxout 单元可以以任意精度近似任何凸函数”。至于放弃凸性后的优化问题可以在结合工程实践来不断改进。 “似乎传统的优化理论结果是残酷的，但我们可以通过**工程方法**和**数学技巧**来尽量规避这些问题，例如启发式方法、增加更多的机器和使用新的硬件（如GPU）。

## 5. 为什么交叉熵损失相比均方误差损失能提高以 sigmoid 和 softmax 作为激活函数的层的性能？

简单来说，就是使用均方误差（MSE）作为损失函数时，会导致大部分情况下**梯度偏小**，其结果就是权重的更新很慢，且容易造成“梯度消失”现象。而交叉熵损失克服了这个缺点，当误差大的时候，权重更新就快，当误差小的时候，权重的更新才慢。

---

问题直白点应该就是输出概率时，为什么用交叉熵损失而不用平方损失？

类似逻辑回归里面的问法，可以从平方损失非凸，且此时更新梯度极小难以更新，分布的角度，目标是伯努力或二项分布，多是采用交叉熵损失。

## 6. 为什么 L1 和 L2 正则化可以防止过拟合？

L1 & L2 正则化会使模型偏好于更小的权值。

简单来说，更小的权值意味着更低的模型复杂度，也就是对训练数据的拟合刚刚好（奥卡姆剃刀），不会过分拟合训练数据（比如异常点，噪声），以提高模型的泛化能力。

此外，*添加正则化相当于为模型添加了某种先验（限制），规定了参数的分布，从而降低了模型的复杂度。*模型的复杂度降低，意味着模型对于噪声与异常点的抗干扰性的能力增强，从而提高模型的泛化能力。

> 参考**算法篇/basic_concepts/Regularization.ipynb**

## 7. 信息熵、KL 散度（相对熵）与交叉熵

前置定义：

**信息量**

在信息论与编码中，信息量，也叫自信息（self-information），是指一个事件所能够带来信息的多少。**一般地，这个事件发生的概率越小，其带来的信息量越大**。从编码的角度来看，这个事件发生的概率越大，其编码长度越小，这个事件发生的概率越小，其编码长度就越大。但是编码长度小也是代价的，比如字母’a’用数字‘0’来表示时，为了避免歧义，就不能有其他任何以‘0’开头的编码了。因此，信息量定义如下：
$$
I = \log_2(\frac{1}{p(x)}) = -\log_2(p(x))
$$

- 信息熵

  信息熵是指一个概率分布$p$的平均信息量，代表随机变量或系统的不确定性，熵越大，随机变量或系统的不确定性就越大（感觉可以理解为信息量太多了，所以比较混乱，即不确定性大）。如果从上面定义的编码角度来看，则信息熵代表一个概率分布$p$需要的平均编码长度，可以表示为：
  $$
  H(p) = \sum_x p(x) \log_2(\frac{1}{p(x)}) = -\sum_x p(x) \log_2 p(x)
  $$

- 交叉熵

  交叉熵是指在给定真实分布q情况下，采用一个猜测的分布p对其进行编码的平均编码长度（或用猜测的分布来编码真实分布得到的信息量）。**交叉熵可以用来衡量真实数据分布于当前分布的相似性**，当前分布与真实分布相等时（q=p），交叉熵达到最小值。其可定义为：
  $$
  H_q(p) = \sum_x q(x) log_2(\frac{1}{p(x)})=-\sum_x q(x) \log_2 p(x)
  $$
  基于交叉熵的性质，许多机器学习算法均采用交叉熵作为损失函数，交叉熵越小，则当前分布与真实分布越接近。

- KL散度

  KL散度又称为**相对熵**，是衡量两个分布之间的差异性。从编码的角度来看，KL散度可表示为采用猜测分布p得到的平均编码长度与采用真实分布q得到的平均编码长度多出的bit数，其数学表达式可定义为：
  $$
  D_q(p) = H_q(p) - H(q) = \sum_x q(x) \log_2(\frac{q(x)}{p(x)})
  $$
  一般地，两个分布越接近，其KL散度则 越小，最小为0。

## 8. 如何避免数值计算中的上溢和下溢问题，以 softmax 为例

- 上溢

  一个很大值被近似为无穷大

- 下溢

  一个很小的数被近似为零

必须对上溢和下溢进行**数值稳定**的一个例子是 **softmax 函数**：
$$
\text{softmax} = \frac{e^{x_i}}{\sum_{j=1}^n e^{x_j}}
$$
因为 softmax 解析上的函数值不会因为从输入向量减去或加上**标量**而改变， 于是一个简单的解决办法是对 x：
$$
x = x - \max_i(x_i)
$$
减去$max_i(x_i)$导致向量的指数运算$e$最大参数为0，排除了上溢的可能性，同样分母中至少一个值为$e^0=1$，这样就排除了因为分母下溢而被零除的可能性。

> 虽然解决了分母中的上溢与下溢问题，但是分子中的下溢仍可以导致整体表达式被计算为零。此时如果计算 log softmax(x) 时，依然要注意可能造成的上溢或下溢问题，处理方法同上。

## 9. 为什么LSTM要优于RNN？

- LSTM可以避免RNN中出现的梯度消失(gradient vanishing)

- 长短期的记忆，记忆的信息更多一些
- 4倍于RNN的参数量，学习到东西更多些

## 10. 为什么LSTM相较于RNN可以缓解梯度消失？

LSTM能解决这个问题是因为:

- 长链C

  LSTM的memory值C是将memory值和input累加的，传统RNN每次都会把之前的memory直接清空

- 门控机制

  LSTM有门控机制，在forget门关闭的情况下，memory的值是不更新的

> 了解[为什么相比于RNN，LSTM在梯度消失上表现更好？](https://www.zhihu.com/question/44895610)
>
> 可以理解为在连乘项中，额外引入偏置信息（可以通过门控机制控制），在连乘时不会是一直较小的数连乘了，i×j×k --> (i+b)×(j+b)×(k+b)；个人觉得这部分的回答就是对应这第一个原因（长链C）

## 11. 深度网络中出现过拟合往往怎么解决？

- 加入正则项

  BN，Dropout，l1/l2

- 修改网络结构

  类似GoogleNet，ResNet，DenseNet等

- 数据增强

- 训练策略（调整参数）

  学习率，epoch，early stopping round，算法集成
  
  > 感觉说选用合适的优化算法比较合适些，用来说机器学习的比较合适
  >
  > 由大到小，检查数据（包括数据增强）-》模型整体参数的调整（epoch 优化算法 batch_size）-》模型内部（加入正则项，降低hidden_size）-》模型的设计（减少层数，降低模型复杂度）

> 数据层面、训练策略、网络结构、网络约束

## 12. Jacobian，Hessian矩阵及其在深度学习中的重要性 

### 12.1 Jacobian

向量分析中,雅可比矩阵是一阶偏导数以一定方式排列成的矩阵。

假设$F: R^n \rightarrow R^m$是一个从欧式$n$维空间转换到欧式$m$维空间的函数。这个函数由$m$个实函数组成，$y1(x_1, x_2, \ldots, x_n), \ldots, ym(x_1, x_2, \ldots, x_n)$，假设这$m$个实函数的偏导数均存在，那么可以组成如下矩阵，
$$
\begin{bmatrix} 
\frac{\partial y1}{\partial x_1} & \cdots & \frac{\partial y1}{\partial x_n} \\ 
\vdots & \ddots & \vdots \\
\frac{\partial ym}{\partial x_1} & \cdots & \frac{\partial ym}{\partial x_n}
\end{bmatrix}
$$
此矩阵可以表示为$J_F(x_1, \ldots, x_n)$或者$\frac{\partial (y1, \ldots, ym)}{\partial (x_1, \ldots, x_n)}$，这个矩阵就是雅克比矩阵。

其重要意义在于它表现了一个多变数向量函数的最佳线性逼近。因此，雅可比矩阵类似于单变数函数的导数。

如果点$P$是$R^n$中的一点，函数$F$在点$P$可微，$J_F(P)$是这一点的导数。在此情况下，$J_F(P)$这个线性映射即函数$F$在点$P$附近的最优线性逼近，也就是说当点$x$足够靠近点$P$时，我们有
$$
F(x) \approx F(P) + J_F(P)(x-P)
$$

> 最后这个最有线性逼近（不就是个泰勒的一阶展开？）不是很懂，搜了下基本上文章都是一大抄，哎

### 12.2 Hessian Matrix

对于函数$f: R^n \rightarrow R$，即$f(x_1, \ldots, x_n)$，假设其二阶偏导均存在，那么函数$f$的海森矩阵如下，
$$
\begin{bmatrix} 
\frac{\partial^2f}{\partial x_1^2} & \cdots & \frac{\partial^2 f}{\partial x_n^2} \\ 
\vdots & \ddots & \vdots \\
\frac{\partial^2 f}{\partial x_1^2} & \cdots & \frac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}
$$
可以表示为$H(f)=D_iD_j f(x)$，海森矩阵主要应用在求根和最优化中，参考**算法篇/OptimizationAlgorithms/NewtonMethod**

## 13. 批梯度下降法（Batch SGD）更新过程中，批的大小会带来怎样的影响？

“**批量**”指使用使用全部训练集；“**小批量**”才用来描述小批量随机梯度下降算法中用到的小批量样本；而**随机梯度下降**（SGD）通常指每次只使用单个样本

**批的大小**通常由以下几个因素决定：

- **较大的批能得到更精确的梯度估计**，但回报是小于线性的。

- 较小的批能带来更好的泛化误差，泛化误差通常在批大小为 1 时最好。但是，因为梯度估计的高方差，小批量训练需要较小的学习率以保持稳定性，这意味着更长的训练时间。

  > 可能是由于小批量在学习过程中加入了噪声，它们会有一些正则化效果 (Wilson and Martinez, 2003)

- **内存消耗和批的大小成正比**，如果批量处理中的所有样本可以并行地处理（通常确是如此）。

- 在某些硬件上使用特定大小可以减少运行时间。尤其是在使用 GPU 时，通常使用 **2 的幂数**作为批量大小可以获得更少的运行时间。一般，2 的幂数的**取值范围是 32 到 256**，16有时在尝试大模型时使用。

- 小批量更容易利用**多核架构**，但是太小的批并不会减少计算时间，这促使我们使用一些**绝对最小批量**

很多机器学习上的优化问题都可以分解成并行地计算不同样本上单独的更新。换言之，我们在计算小批量样本 X 上最小化 J(X) 的更新时，同时可以计算其他小批量样本上的更新。

## 14. 批标准化（Batch Normalization）的意义？

批标准化（Batch Normalization, BN, Ioffe and Szegedy, 2015）是为了克服神经网络**层数加深导致难以训练**而出现的一个算法。

**优点：**

- 允许较大的学习率，加快模型收敛速度   
BN通过固定网络层输入（也即前一层的响应）的分布（标准正态）使优化过程中的解空间更平滑，从而确保了梯度更具预测性和稳定性，因此可以使用更大范围的学习率并获得更快的收敛速度。

- 避免深层网络的梯度消失或爆炸问题   
BN通过固定网络层输入的均值和方差，即使网络较深层的响应或梯度过小或过大时，也可通过BN的规范化作用将其缩放到一个比较合理的取值范围，从而避免梯度消失或爆炸问题。

- 减少对参数初始化方法的依赖    
Xavier等参数初始化的目的是为了使网络各层的输入输出具有相同的统计分布，而BN直接对网络层构造标准正态分布的响应，能够达到同样的目的。 

**缺点：**

batch normalization依赖于batch的大小，当batch值很小时，计算的均值和方差不稳定。研究表明对于ResNet类模型在ImageNet数据集上，batch从16降低到8时开始有非常明显的性能下降，在训练过程中计算的均值和方差不准确，而在测试的时候使用的就是训练过程中保持下来的均值和方差。

这一个特性，导致batch normalization不适合以下的几种场景。

(1)batch非常小，比如训练资源有限无法应用较大的batch，也比如在线学习等使用单例进行模型参数更新的场景。

(2)rnn，因为它是一个动态的网络结构，同一个batch中训练实例有长有短，导致每一个时间步长必须维持各自的统计量，这使得BN并不能正确的使用。在rnn中，对bn进行改进也非常的困难。不过，困难并不意味着没人做，事实上现在仍然可以使用的，不过这超出了咱们初识境的学习范围。

参考：[深度学习中 Batch Normalization为什么效果好？](https://www.zhihu.com/question/38102762/answer/85238569) 

## 15. 深度学习中如何调参，或者调参策略是什么？

类似机器学习，刚开始不要加入过多内容（比如dropout/BN等正则），简单的设置一下epoch和学习率观察验证集的变化情况，然后根据此进行调整。

然后根据训练集和验证集的反应来判断，如果过拟合，调整网络参数（模型参数），加入正则项、数据增强，调整整体参数，加入早停机制等等（相当于是问题11）；

如果欠拟合，同样调整网络参数，增加epoch啦学习率啥的；如果出现一些极端反应，比如训练集loss在不断上升，反而验证集loss下降，有必要查看数据和代码，有必要的情况下，看看是不是loss定义的有问题，是不是需要更换loss。

## 16. **交叉熵函数**与**最大似然函数**的联系和区别？

区别：**交叉熵函数**使用来描述模型预测值和真实值的差距大小，越大代表越不相近；**似然函数**的本质就是衡量在某个参数下，整体的估计和真实的情况一样的概率，越大代表越相近。

> 可以理解为两者的出发点不一致

联系：**交叉熵函数**可以由最大似然函数在伯努利分布的条件下推导出来，或者说**最小化交叉熵函数**的本质就是**对数似然函数的最大化**。

> 可以通过最大化似然函数的方式推导得出交叉熵函数

## 17. 神经网络中，如果初始化参数为0，会有什么后果，如果为相同值的呢？

所有参数将得不到更新，会陷一个僵局。

以三层的前馈神经网络（输入、隐含和输出）为例，

假设输入$x \in R^m$，隐含层$h \in R^n$，输出层$y \in R^l$。

假设输入和隐含层的连接参数为$w_{ij}, i=1,..,m, j=1,..,n$，隐含层和输出层的连接参数为$v_{jk}, j=1,..,n, k=1,..,l$。

那么前馈的表达式为，$h_j = \sum_{i=1}^m w_{ij}x_j, \hat{h_j} = f(h_j), \hat{y_k}=\sum_{j=1}^n v_{jk}\hat{h_j}$。

记单个样本的loss为$L = \sum_{k=1}^l loss(y_k, \hat{y_k})$。

其中包含两部分参数，分别为$w_{ij}$和$v_{jk}$。那么BP的表达式为
$$
\begin{cases}
\frac{\partial L}{\partial v_{jk}} &= \frac{\partial L}{\partial \hat{y_k}} \cdot \frac{\partial \hat{y_k}}{\partial v_{jk}} \\ 
&= \frac{\partial L}{\partial \hat{y_k}} \cdot \hat{h_j}\\
\frac{\partial L}{\partial w_{ij}} &= [\sum_{k=1}^l \frac{\partial L}{\partial \hat{y_k}}\cdot \frac{\partial \hat{y_k}}{\partial \hat{h_j}}] \cdot \frac{\partial \hat{h_j}}{\partial h_j}\cdot\frac{\partial h_j}{\partial w_{ij}} \\ 
&= [\sum_{k=1}^l \frac{\partial L}{\partial \hat{y_k}}\cdot v_{jk}] \cdot \frac{\partial \hat{h_j}}{\partial h_j}\cdot\frac{\partial h_j}{\partial w_{ij}}
\end{cases}
$$
更新如下，
$$
w_{ij} = w_{ij} - \eta \frac{\partial L}{\partial w_{ij}} \\
v_{ij} = v_{ij} - \eta \frac{\partial L}{\partial v_{ij}}
$$
如果初始化参数全部为0，可发现此时$\frac{\partial L}{\partial w_{ij}}=0$，此时按照上面的方式更新之后，仍然有$w_{ij}=0$，将无法得到更新。

如果设置为相同值，此时参数可以更新了但是每一层的参数是相同的，相当于缩小了模型的容量。

## 18. Batch Normalization和Layer Normalization的区别

参考[文章](https://www.cnblogs.com/dyl222/p/12197187.html)

## 19. 为什么要对数据做归一化

神经网络学习过程本质就是为了学习数据特征以及数据的分布特征，一旦训练数据与测试数据的分布不同，那么网络的泛化能力也大大降低；（模型的泛化能力）

另外一方面，一旦每批训练数据的分布各不相同(batch 梯度下降)，那么网络就要在每次迭代都去学习适应不同的分布，这样将会大大降低网络的训练速度，这也正是为什么我们需要对数据都要做一个归一化预处理的原因。（模型的训练时收敛的速度）

同时也是在训练前为什么要把训练数据充分打乱的原因，充分打乱使得每个batch的样本包含各类别的数据，这样通过每个batch的样本训练时各个batch所包含的数据分布更接近，同时和整个训练集的数据分布更接近，更有利于训练出更泛化的模型，同时有利于模型的收敛。试想不充分打乱数据，若每个batch只包含一个类别的数据，不同的batch数据进行训练时网络就要在每次迭代都去学习适应不同的分布，会使得网络收敛很慢。

## 20. 多层fc和少量层fc，多层lstm堆叠和少量层lstm堆叠的优缺点



## 更新算法和激活函数的相关问题，补充



# CNN相关问题



# RNN相关问题

